<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python 数据类型]]></title>
    <url>%2F2017%2F12%2F04%2Fpython2%2F</url>
    <content type="text"><![CDATA[数据类型在Python中，能够直接处理的数据类型有以下几种： 基本数据类型整数Python可以处理任意大小的整数，当然包括负整数，在程序中的表示方法和数学上的写法一模一样，例如：1，100，-8080，0，等等。计算机由于使用二进制，所以，有时候用十六进制表示整数比较方便，十六进制用0x前缀和0-9，a-f表示，例如：0xff00，0xa5b4c3d2，等等。 浮点数浮点数也就是小数，之所以称为浮点数，是因为按照科学记数法表示时，一个浮点数的小数点位置是可变的，浮点数可以用数学写法，如1.23，3.14，-9.01，等等。但是对于很大或很小的浮点数，就必须用科学计数法表示，把10用e替代，1.23x109就是1.23e9，或者12.3e8，0.000012可以写成1.2e-5，等等。 字符串字符串是以’’或””括起来的任意文本，比如&#39;abc&#39;，&quot;xyz&quot;等等。请注意，&#39;&#39;或&quot;&quot;本身只是一种表示方式，不是字符串的一部分，因此，字符串&#39;abc&#39;只有a，b，c这3个字符。如果&#39;本身也是一个字符，那就可以用&quot;&quot;括起来，比如&quot;I&#39;m OK&quot;包含的字符是I，&#39;，m，空格，O，K这6个字符。如果字符串内部既包含&#39;又包含&quot;怎么办？可以用转义字符\来标识，比如：&#39;I\&#39;m \&quot;OK\&quot;!&#39;表示的字符串内容是：I&#39;m &quot;OK&quot;! 布尔值布尔值和布尔代数的表示完全一致，一个布尔值只有True、False两种值，要么是True，要么是False，在Python中，可以直接用True、False表示布尔值（请注意大小写），也可以通过布尔运算计算出来：12345678print TrueTrueprint FalseFalseprint 3 &gt; 2Trueprint 3 &gt; 5False 布尔值可以用and、or和not运算。 空值空值是Python里一个特殊的值，用None表示。None不能理解为0，因为0是有意义的，而None是一个特殊的空值。 变量变量名必须是大小写英文、数字和_的组合，且不能用数字开头 ##数据类型进阶 列表（list）Python内置的一种数据类型是列表：list。list是一种有序的集合，可以随时添加和删除其中的元素。声明list：list=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]用索引来访问list中每一个位置的元素，记得索引是从0开始的例如list [0]如果要取最后一个元素，除了计算索引位置外，还可以用-1做索引，直接获取最后一个元素：list[-1]list是一个可变的有序表，所以，可以往list中追加元素到末尾：list.append([指定位置]&#39;aaa&#39;)要删除list的元素，用pop()方法：list.pop([指定位置默认为最后])要把某个元素替换成别的元素，可以直接赋值给对应的索引位置,list里面的元素的数据类型也可以不同。list元素也可以是另一个list,例如：s = [&#39;python&#39;, &#39;java&#39;, [&#39;asp&#39;, &#39;php&#39;], &#39;scheme&#39;] 元祖（tuple）另一种有序列表叫元组：tuple。tuple和list非常类似，但是tuple一旦初始化就不能修改声明元祖t=（1，2）只有1个元素的tuple定义时必须加一个逗号,，来消除歧义：t=(1,)最后来看一个“可变的”tuple：123t = (&apos;a&apos;, &apos;b&apos;, [&apos;A&apos;, &apos;B&apos;])t[2][0] = &apos;X&apos;t[2][0] = &apos;X&apos; 字典（dict）Python内置了字典：dict的支持，dict全称dictionary，在其他语言中也称为map，使用键-值（key-value）存储，具有极快的查找速度。声明dict d = {&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3} setset和dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中，没有重复的key。要创建一个set，需要提供一个list作为输入集合:声明 set s = set([1,2,3])set可以看成数学意义上的无序和无重复元素的集合，因此，两个set可以做数学意义上的交集、并集等操作：123456print s1 = set([1, 2, 3])print s2 = set([2, 3, 4])print s1 &amp; s2set([2, 3])print s1 | s2set([1, 2, 3, 4])]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>-python 语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 安装]]></title>
    <url>%2F2017%2F12%2F04%2FPython%2F</url>
    <content type="text"><![CDATA[python 环境准备安装 Python 首先从Python的官方网站python.org下载最新的2.7版本，网速慢的同学请移步国内镜像。 然后，运行下载的MSI安装包，在选择安装组件的一步时，勾上所有的组件： 特别要注意选上pip和Add python.exe to Path，然后一路点“Next”即可完成安装。 默认会安装到C:\Python27目录下，然后打开命令提示符窗口，敲入python后，会出现两种情况。情况一：看到上面的画面，就说明Python安装成功！你看到提示符&gt;&gt;&gt;就表示我们已经在Python交互式环境中了，可以输入任何Python代码，回车后会立刻得到执行结果。现在，输入exit()并回车，就可以退出Python交互式环境（直接关掉命令行窗口也可以！）。情况二：得到一个错误： ‘python’不是内部或外部命令，也不是可运行的程序或批处理文件。 这是因为Windows会根据一个Path的环境变量设定的路径去查找python.exe，如果没找到，就会报错。如果在安装时漏掉了勾选Add python.exe to Path，那就要手动把python.exe所在的路径C:\Python27添加到Path中。 如果你不知道怎么修改环境变量，建议把Python安装程序重新运行一遍，记得勾上Add python.exe to Path。安装 pycharm 首先从网站下载pycharm: http://www.jetbrains.com/pycharm/download/#section=windows，进入之后如下图，根据自己电脑的操作系统进行选择，对于windows系统选择图中红色圈中的区域。 下载完成之后如下图： 直接双击下载好的exe文件进行安装,点击Next进入下一步： 点击Install进行安装 安装完成后出现下图界面，点级Finish结束安装使用pycharm 单击桌面上的pycharm图标，进入到pycharm中 我们选择第二个，然后点击Ok 点击Accept进入下一步： 点击上图中的ok进入下一步：至此，安装完成]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python re]]></title>
    <url>%2F2017%2F12%2F04%2Fpython3%2F</url>
    <content type="text"><![CDATA[#了解正则表达式 正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。正则表达式是用来匹配字符串非常强大的工具，在其他编程语言中同样有正则表达式的概念，Python同样不例外，利用了正则表达式，我们想要从返回的页面内容提取出我们想要的内容就易如反掌了。正则表达式的大致匹配过程是：1.依次拿出表达式和文本中的字符比较，2.如果每一个字符都能匹配，则匹配成功；一旦有匹配不成功的字符则匹配失败。3.如果表达式中有量词或边界，这个过程会稍微有一些不同。 正则表达式的语法规则正则表达式的语法规则 正则表达式相关注解正则表达式通常用于在文本中查找匹配的字符串。Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字 符；非贪婪的则相反，总是尝试匹配尽可能少的字符。例如：正则表达式”ab”如果用于查找”abbbc”，将找到”abbb”。而如果使用非贪婪的数量 词”ab*?”，将找到”a”。注：我们一般使用非贪婪模式来提取。 反斜杠问题Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\”表示。同样，匹配一个数字的”\d”可以写成r”\d”。有了原生字符串，妈妈也不用担心是不是漏写了反斜杠，写出来的表达式也更直观。 Python Re模块Python 自带了re模块，它提供了对正则表达式的支持。主要用到的方法列举如下：123456789101112import reA=&apos;12a88b22b368d8&apos; #查找所有的数字 +表示一次 或者多次 ？表示0次或者一次 *表示一次或者多次print re.findall(&apos;\d+&apos;,A)#查找所有的数字 返回一个对象obj_A=re.finditer(&apos;\d+&apos;,A)for i in obj_A: print i.group()#第一个参数为正则表达式 第二个参数想要替换成什么 第三个参数为替换的字符串print re.sub(r&apos;\d&apos;,&apos;z&apos;,A,2,flags=re.I)re.purge() #清空正则表达式缓存 re.split(pattern, string[, maxsplit])按照能够匹配的子串将string分割后返回列表。maxsplit用于指定最大分割次数，不指定将全部分割。1234567import repattern = re.compile(r&apos;\d+&apos;)print re.split(pattern,&apos;one1two2three3four4&apos;)### 输出 #### [&apos;one&apos;, &apos;two&apos;, &apos;three&apos;, &apos;four&apos;, &apos;&apos;] re.findall(pattern, string[, flags])搜索string，以列表形式返回全部能匹配的子串。1234567import repattern = re.compile(r&apos;\d+&apos;)print re.findall(pattern,&apos;one1two2three3four4&apos;)### 输出 #### [&apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;] re.sub(pattern, repl, string[, count])Python – 伯乐在线首页所有文章观点与动态基础知识系列教程实践项目工具与框架工具资源Python小组伯乐在线 &gt; Python - 伯乐在线 &gt; 所有文章 &gt; 实践项目 &gt; Python爬虫入门（7）：正则表达式Python爬虫入门（7）：正则表达式 2015/04/25 · 实践项目, 系列教程 · 3 评论 · 爬虫分享到： 27本文作者： 伯乐在线 - 崔庆才 。未经作者许可，禁止转载！欢迎加入伯乐在线 专栏作者。Python爬虫入门（1）：综述Python爬虫入门（2）：爬虫基础了解Python爬虫入门（3）：Urllib库的基本使用Python爬虫入门（4）：Urllib库的高级用法Python爬虫入门（5）：URLError异常处理Python爬虫入门（6）：Cookie的使用Python爬虫入门（7）：正则表达式Python爬虫入门（8）：Beautiful Soup的用法在前面我们已经搞定了怎样获取页面的内容，不过还差一步，这么多杂乱的代码夹杂文字我们怎样把它提取出来整理呢？下面就开始介绍一个十分强大的工具，正则表达式！ 1.了解正则表达式 正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。正则表达式是用来匹配字符串非常强大的工具，在其他编程语言中同样有正则表达式的概念，Python同样不例外，利用了正则表达式，我们想要从返回的页面内容提取出我们想要的内容就易如反掌了。 正则表达式的大致匹配过程是：1.依次拿出表达式和文本中的字符比较，2.如果每一个字符都能匹配，则匹配成功；一旦有匹配不成功的字符则匹配失败。3.如果表达式中有量词或边界，这个过程会稍微有一些不同。2.正则表达式的语法规则 下面是Python中正则表达式的一些匹配规则，图片资料来自CSDN 20130515113723855 3.正则表达式相关注解 （1）数量词的贪婪模式与非贪婪模式 正则表达式通常用于在文本中查找匹配的字符串。Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字 符；非贪婪的则相反，总是尝试匹配尽可能少的字符。例如：正则表达式”ab”如果用于查找”abbbc”，将找到”abbb”。而如果使用非贪婪的数量 词”ab?”，将找到”a”。 注：我们一般使用非贪婪模式来提取。 （2）反斜杠问题 与大多数编程语言相 同，正则表达式里使用”\”作为转义字符，这就可能造成反斜杠困扰。假如你需要匹配文本中的字符”\”，那么使用编程语言表示的正则表达式里将需要4个反 斜杠”\\”：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。 Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\”表示。同样，匹配一个数字的”\d”可以写成r”\d”。有了原生字符串，妈妈也不用担心是不是漏写了反斜杠，写出来的表达式也更直观勒。 4.Python Re模块 Python 自带了re模块，它提供了对正则表达式的支持。主要用到的方法列举如下 Python #返回pattern对象re.compile(string[,flag]) #以下为匹配所用函数re.match(pattern, string[, flags])re.search(pattern, string[, flags])re.split(pattern, string[, maxsplit])re.findall(pattern, string[, flags])re.finditer(pattern, string[, flags])re.sub(pattern, repl, string[, count])re.subn(pattern, repl, string[, count])12345678910 #返回pattern对象re.compile(string[,flag]) #以下为匹配所用函数re.match(pattern, string[, flags])re.search(pattern, string[, flags])re.split(pattern, string[, maxsplit])re.findall(pattern, string[, flags])re.finditer(pattern, string[, flags])re.sub(pattern, repl, string[, count])re.subn(pattern, repl, string[, count])在介绍这几个方法之前，我们先来介绍一下pattern的概念，pattern可以理解为一个匹配模式，那么我们怎么获得这个匹配模式呢？很简单，我们需要利用re.compile方法就可以。例如 Python pattern = re.compile(r’hello’)1pattern = re.compile(r’hello’)在参数中我们传入了原生字符串对象，通过compile方法编译生成一个pattern对象，然后我们利用这个对象来进行进一步的匹配。 另外大家可能注意到了另一个参数 flags，在这里解释一下这个参数的含义： 参数flag是匹配模式，取值可以使用按位或运算符’|’表示同时生效，比如re.I | re.M。 可选值有： Python • re.I(全拼：IGNORECASE): 忽略大小写（括号内是完整写法，下同） • re.M(全拼：MULTILINE): 多行模式，改变’^’和’$’的行为（参见上图） • re.S(全拼：DOTALL): 点任意匹配模式，改变’.’的行为 • re.L(全拼：LOCALE): 使预定字符类 \w \W \b \B \s \S 取决于当前区域设定 • re.U(全拼：UNICODE): 使预定字符类 \w \W \b \B \s \S \d \D 取决于unicode定义的字符属性 • re.X(全拼：VERBOSE): 详细模式。这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释。123456 • re.I(全拼：IGNORECASE): 忽略大小写（括号内是完整写法，下同） • re.M(全拼：MULTILINE): 多行模式，改变’^’和’$’的行为（参见上图） • re.S(全拼：DOTALL): 点任意匹配模式，改变’.’的行为 • re.L(全拼：LOCALE): 使预定字符类 \w \W \b \B \s \S 取决于当前区域设定 • re.U(全拼：UNICODE): 使预定字符类 \w \W \b \B \s \S \d \D 取决于unicode定义的字符属性 • re.X(全拼：VERBOSE): 详细模式。这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释。在刚才所说的另外几个方法例如 re.match 里我们就需要用到这个pattern了，下面我们一一介绍。 注：以下七个方法中的flags同样是代表匹配模式的意思，如果在pattern生成时已经指明了flags，那么在下面的方法中就不需要传入这个参数了。（1）re.match(pattern, string[, flags]) 这个方法将会从string（我们要匹配的字符串）的开头开始，尝试匹配pattern，一直向后匹配，如果遇到无法匹配的字符，立即返回 None，如果匹配未结束已经到达string的末尾，也会返回None。两个结果均表示匹配失败，否则匹配pattern成功，同时匹配终止，不再对 string向后匹配。下面我们通过一个例子理解一下 Python author = ‘CQC’ -- coding: utf-8 --#导入re模块import re 将正则表达式编译成Pattern对象，注意hello前面的r的意思是“原生字符串”pattern = re.compile(r’hello’) 使用re.match匹配文本，获得匹配结果，无法匹配时将返回Noneresult1 = re.match(pattern,’hello’)result2 = re.match(pattern,’helloo CQC!’)result3 = re.match(pattern,’helo CQC!’)result4 = re.match(pattern,’hello CQC!’) #如果1匹配成功if result1: # 使用Match获得分组信息 print result1.group() else: print ‘1匹配失败！’ #如果2匹配成功if result2: # 使用Match获得分组信息 print result2.group() else: print ‘2匹配失败！’ #如果3匹配成功if result3: # 使用Match获得分组信息 print result3.group() else: print ‘3匹配失败！’ #如果4匹配成功if result4: # 使用Match获得分组信息 print result4.group() else: print ‘4匹配失败！’123456789101112131415161718192021222324252627282930313233343536373839404142author = ‘CQC’ -- coding: utf-8 --#导入re模块import re 将正则表达式编译成Pattern对象，注意hello前面的r的意思是“原生字符串”pattern = re.compile(r’hello’) 使用re.match匹配文本，获得匹配结果，无法匹配时将返回Noneresult1 = re.match(pattern,’hello’)result2 = re.match(pattern,’helloo CQC!’)result3 = re.match(pattern,’helo CQC!’)result4 = re.match(pattern,’hello CQC!’) #如果1匹配成功if result1: # 使用Match获得分组信息 print result1.group() else: print ‘1匹配失败！’ #如果2匹配成功if result2: # 使用Match获得分组信息 print result2.group() else: print ‘2匹配失败！’ #如果3匹配成功if result3: # 使用Match获得分组信息 print result3.group() else: print ‘3匹配失败！’ #如果4匹配成功if result4: # 使用Match获得分组信息 print result4.group() else: print ‘4匹配失败！’运行结果 Python hellohello3匹配失败！hello1234hellohello3匹配失败！hello匹配分析 1.第一个匹配，pattern正则表达式为’hello’，我们匹配的目标字符串string也为hello，从头至尾完全匹配，匹配成功。 2.第二个匹配，string为helloo CQC，从string头开始匹配pattern完全可以匹配，pattern匹配结束，同时匹配终止，后面的o CQC不再匹配，返回匹配成功的信息。 3.第三个匹配，string为helo CQC，从string头开始匹配pattern，发现到 ‘o’ 时无法完成匹配，匹配终止，返回None 4.第四个匹配，同第二个匹配原理，即使遇到了空格符也不会受影响。 我们还看到最后打印出了result.group()，这个是什么意思呢？下面我们说一下关于match对象的的属性和方法Match对象是一次匹配的结果，包含了很多关于此次匹配的信息，可以使用Match提供的可读属性或方法来获取这些信息。 属性：1.string: 匹配时使用的文本。2.re: 匹配时使用的Pattern对象。3.pos: 文本中正则表达式开始搜索的索引。值与Pattern.match()和Pattern.seach()方法的同名参数相同。4.endpos: 文本中正则表达式结束搜索的索引。值与Pattern.match()和Pattern.seach()方法的同名参数相同。5.lastindex: 最后一个被捕获的分组在文本中的索引。如果没有被捕获的分组，将为None。6.lastgroup: 最后一个被捕获的分组的别名。如果这个分组没有别名或者没有被捕获的分组，将为None。 方法：1.group([group1, …]):获得一个或多个分组截获的字符串；指定多个参数时将以元组形式返回。group1可以使用编号也可以使用别名；编号0代表整个匹配的子串；不填写参数时，返回group(0)；没有截获字符串的组返回None；截获了多次的组返回最后一次截获的子串。2.groups([default]):以元组形式返回全部分组截获的字符串。相当于调用group(1,2,…last)。default表示没有截获字符串的组以这个值替代，默认为None。3.groupdict([default]):返回以有别名的组的别名为键、以该组截获的子串为值的字典，没有别名的组不包含在内。default含义同上。4.start([group]):返回指定的组截获的子串在string中的起始索引（子串第一个字符的索引）。group默认值为0。5.end([group]):返回指定的组截获的子串在string中的结束索引（子串最后一个字符的索引+1）。group默认值为0。6.span([group]):返回(start(group), end(group))。7.expand(template):将匹配到的分组代入template中然后返回。template中可以使用\id或\g、\g引用分组，但不能使用编号0。\id与\g是等价的；但\10将被认为是第10个分组，如果你想表达\1之后是字符’0’，只能使用\g0。下面我们用一个例子来体会一下 Python -- coding: utf-8 --#一个简单的match实例 import re 匹配如下内容：单词+空格+单词+任意字符m = re.match(r’(\w+) (\w+)(?P.*)’, ‘hello world!’) print “m.string:”, m.stringprint “m.re:”, m.reprint “m.pos:”, m.posprint “m.endpos:”, m.endposprint “m.lastindex:”, m.lastindexprint “m.lastgroup:”, m.lastgroupprint “m.group():”, m.group()print “m.group(1,2):”, m.group(1, 2)print “m.groups():”, m.groups()print “m.groupdict():”, m.groupdict()print “m.start(2):”, m.start(2)print “m.end(2):”, m.end(2)print “m.span(2):”, m.span(2)print r”m.expand(r’\g \g\g’):”, m.expand(r’\2 \1\3’) outputm.string: hello world!m.re:m.pos: 0m.endpos: 12m.lastindex: 3m.lastgroup: signm.group(1,2): (‘hello’, ‘world’)m.groups(): (‘hello’, ‘world’, ‘!’)m.groupdict(): {‘sign’: ‘!’}m.start(2): 6m.end(2): 11m.span(2): (6, 11)m.expand(r’\2 \1\3’): world hello!123456789101112131415161718192021222324252627282930313233343536 -- coding: utf-8 --#一个简单的match实例 import re 匹配如下内容：单词+空格+单词+任意字符m = re.match(r’(\w+) (\w+)(?P.*)’, ‘hello world!’) print “m.string:”, m.stringprint “m.re:”, m.reprint “m.pos:”, m.posprint “m.endpos:”, m.endposprint “m.lastindex:”, m.lastindexprint “m.lastgroup:”, m.lastgroupprint “m.group():”, m.group()print “m.group(1,2):”, m.group(1, 2)print “m.groups():”, m.groups()print “m.groupdict():”, m.groupdict()print “m.start(2):”, m.start(2)print “m.end(2):”, m.end(2)print “m.span(2):”, m.span(2)print r”m.expand(r’\g \g\g’):”, m.expand(r’\2 \1\3’) outputm.string: hello world!m.re:m.pos: 0m.endpos: 12m.lastindex: 3m.lastgroup: signm.group(1,2): (‘hello’, ‘world’)m.groups(): (‘hello’, ‘world’, ‘!’)m.groupdict(): {‘sign’: ‘!’}m.start(2): 6m.end(2): 11m.span(2): (6, 11)m.expand(r’\2 \1\3’): world hello!（2）re.search(pattern, string[, flags]) search方法与match方法极其类似，区别在于match()函数只检测re是不是在string的开始位置匹配，search()会扫描整个string查找匹配，match（）只有在0位置匹配成功的话才有返回，如果不是开始位置匹配成功的话，match()就返回None。同样，search方法的返回对象同样match()返回对象的方法和属性。我们用一个例子感受一下 Python #导入re模块import re 将正则表达式编译成Pattern对象pattern = re.compile(r’world’) 使用search()查找匹配的子串，不存在能匹配的子串时将返回None这个例子中使用match()无法成功匹配match = re.search(pattern,’hello world!’)if match: # 使用Match获得分组信息 print match.group() 输出world12345678910111213 #导入re模块import re 将正则表达式编译成Pattern对象pattern = re.compile(r’world’) 使用search()查找匹配的子串，不存在能匹配的子串时将返回None这个例子中使用match()无法成功匹配match = re.search(pattern,’hello world!’)if match: # 使用Match获得分组信息 print match.group() 输出world（3）re.split(pattern, string[, maxsplit]) 按照能够匹配的子串将string分割后返回列表。maxsplit用于指定最大分割次数，不指定将全部分割。我们通过下面的例子感受一下。 Python import re pattern = re.compile(r’\d+’)print re.split(pattern,’one1two2three3four4’) 输出[‘one’, ‘two’, ‘three’, ‘four’, ‘’]1234567import re pattern = re.compile(r’\d+’)print re.split(pattern,’one1two2three3four4’) 输出[‘one’, ‘two’, ‘three’, ‘four’, ‘’]（4）re.findall(pattern, string[, flags]) 搜索string，以列表形式返回全部能匹配的子串。我们通过这个例子来感受一下 Python import re pattern = re.compile(r’\d+’)print re.findall(pattern,’one1two2three3four4’) 输出[‘1’, ‘2’, ‘3’, ‘4’]1234567import re pattern = re.compile(r’\d+’)print re.findall(pattern,’one1two2three3four4’) 输出[‘1’, ‘2’, ‘3’, ‘4’]（5）re.finditer(pattern, string[, flags]) 搜索string，返回一个顺序访问每一个匹配结果（Match对象）的迭代器。我们通过下面的例子来感受一下 Python import re pattern = re.compile(r’\d+’)for m in re.finditer(pattern,’one1two2three3four4’): print m.group(), 输出1 2 3 412345678import re pattern = re.compile(r’\d+’)for m in re.finditer(pattern,’one1two2three3four4’): print m.group(), 输出1 2 3 4（6）re.sub(pattern, repl, string[, count]) 使用repl替换string中每一个匹配的子串后返回替换后的字符串。当repl是一个字符串时，可以使用\id或\g、\g引用分组，但不能使用编号0。当repl是一个方法时，这个方法应当只接受一个参数（Match对象），并返回一个字符串用于替换（返回的字符串中不能再引用分组）。count用于指定最多替换次数，不指定时全部替换。123456789101112131415import repattern = re.compile(r&apos;(\w+) (\w+)&apos;)s = &apos;i say, hello world!&apos;print re.sub(pattern,r&apos;\2 \1&apos;, s)def func(m): return m.group(1).title() + &apos; &apos; + m.group(2).title()print re.sub(pattern,func, s)### output #### say i, world hello!# I Say, Hello World!]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python 安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件名]]></title>
    <url>%2F2017%2F12%2F04%2F%E6%96%87%E4%BB%B6%E5%90%8D%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[java]]></title>
    <url>%2F2017%2F12%2F04%2FJava%2F</url>
    <content type="text"></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>-java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫认知]]></title>
    <url>%2F2017%2F12%2F04%2F%E7%88%AC%E8%99%AB%2F</url>
    <content type="text"><![CDATA[综述大家好，最近博主在学习Python，学习期间也遇到一些问题，获得了一些经验，在此将自己的学习系统地整理下来，如果大家有兴趣学习爬虫的话，可以将这些文章作为参考，也欢迎大家一共分享学习经验。 Python版本:2.7，Python 3请另寻其他博文。 根据我的经验，要学习Python爬虫，我们要学习的共有以下几点： Python基础知识 Python中urllib和urllib2库的用法 Python正则表达式 Python爬虫框架Scrapy Python爬虫更高级的功能 Python基础学习首先，我们要用Python写爬虫，肯定要了解Python的基础吧，万丈高楼平地起，不能忘啦那地基，哈哈，那么我就分享一下自己曾经看过的一些Python教程，小伙伴们可以作为参考。 慕课网Python教程曾经有一些基础的语法是在慕课网上看的，上面附有一些练习，学习完之后可以作为练习，感觉效果还是蛮不错的，不过稍微遗憾的是内容基本上都是最基础的，入门开始的话，就这个吧 学习网址：https://www.imooc.com/course/list?c=python 廖雪峰Python教程后来，我发现了廖老师的Python教程，讲的那是非常通俗易懂哪，感觉也是非常不错，大家如果想进一步了解Python就看一下这个吧。 学习网址：https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000 Python urllib和urllib2 库的用法urllib和urllib2库是学习Python爬虫最基本的库，利用这个库我们可以得到网页的内容，并对内容用正则表达式提取分析，得到我们想要的结果。这个在学习过程中我会和大家分享的。 Python 正则表达式Python正则表达式是一种用来匹配字符串的强有力的武器。它的设计思想是用一种描述性的语言来给字符串定义一个规则，凡是符合规则的字符串，我们就认为它“匹配”了，否则，该字符串就是不合法的。这个在后面的博文会分享的。 爬虫框架Scrapy如果你是一个Python高手，基本的爬虫知识都已经掌握了，那么就寻觅一下Python框架吧，我选择的框架是Scrapy框架。这个框架有什么强大的功能呢？下面是它的官方介绍： HTML, XML源数据 选择及提取 的内置支持提供了一系列在spider之间共享的可复用的过滤器(即 Item Loaders)，对智能处理爬取数据提供了内置支持。通过 feed导出 提供了多格式(JSON、CSV、XML)，多存储后端(FTP、S3、本地文件系统)的内置支持提供了media pipeline，可以 自动下载 爬取到的数据中的图片(或者其他资源)。高扩展性。您可以通过使用 signals ，设计好的API(中间件, extensions, pipelines)来定制实现您的功能。内置的中间件及扩展为下列功能提供了支持:cookies and session 处理HTTP 压缩HTTP 认证HTTP 缓存user-agent模拟robots.txt爬取深度限制针对非英语语系中不标准或者错误的编码声明, 提供了自动检测以及健壮的编码支持。支持根据模板生成爬虫。在加速爬虫创建的同时，保持在大型项目中的代码更为一致。详细内容请参阅 genspider 命令。针对多爬虫下性能评估、失败检测，提供了可扩展的 状态收集工具 。提供 交互式shell终端 , 为您测试XPath表达式，编写和调试爬虫提供了极大的方便提供 System service, 简化在生产环境的部署及运行内置 Web service, 使您可以监视及控制您的机器内置 Telnet终端 ，通过在Scrapy进程中钩入Python终端，使您可以查看并且调试爬虫Logging 为您在爬取过程中捕捉错误提供了方便支持 Sitemaps 爬取具有缓存的DNS解析器 官方文档：http://doc.scrapy.org/en/latest/ 爬虫基础了解什么是爬虫爬虫，即网络爬虫，大家可以理解为在网络上爬行的一直蜘蛛，互联网就比作一张大网，而爬虫便是在这张网上爬来爬去的蜘蛛咯，如果它遇到资源，那么它就会抓取下来。想抓取什么？这个由你来控制它咯。比如它在抓取一个网页，在这个网中他发现了一条道路，其实就是指向网页的超链接，那么它就可以爬到另一张网上来获取数据。这样，整个连在一起的大网对这之蜘蛛来说触手可及，分分钟爬下来不是事儿。 浏览网页的过程在用户浏览网页的过程中，我们可能会看到许多好看的图片，比如 http://image.baidu.com/ ，我们会看到几张的图片以及百度搜索框，这个过程其实就是用户输入网址之后，经过DNS服务器，找到服务器主机，向服务器发出一个请求，服务器经过解析之后，发送给用户的浏览器 HTML、JS、CSS 等文件，浏览器解析出来，用户便可以看到形形色色的图片了。 URL的含义URL，即统一资源定位符，也就是我们说的网址，统一资源定位符是对可以从互联网上得到的资源的位置和访问方法的一种简洁的表示，是互联网上标准资源的地址。互联网上的每个文件都有一个唯一的URL，它包含的信息指出文件的位置以及浏览器应该怎么处理它。URL的格式由三部分组成： ①第一部分是协议(或称为服务方式)。 ②第二部分是存有该资源的主机IP地址(有时也包括端口号)。 ③第三部分是主机资源的具体地址，如目录和文件名等。爬虫爬取数据时必须要有一个目标的URL才可以获取数据，因此，它是爬虫获取数据的基本依据，准确理解它的含义对爬虫学习有很大帮助。 环境的配置学习Python，当然少不了环境的配置，最初我用的是Sublime，不过发现它没有提示功能实在是太弱了，于是，在Windows下我用了 PyCharm.]]></content>
      <categories>
        <category>Python</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Urllib库]]></title>
    <url>%2F2017%2F12%2F04%2F%E7%88%AC%E8%99%AB2%2F</url>
    <content type="text"><![CDATA[urllib库的使用扒一个网页怎样扒网页呢？其实就是根据URL来获取它的网页信息，虽然我们在浏览器中看到的是一幅幅优美的画面，但是其实是由浏览器解释才呈现出来的，实质它 是一段HTML代码，加 JS、CSS，如果把网页比作一个人，那么HTML便是他的骨架，JS便是他的肌肉，CSS便是它的衣服。所以最重要的部分是存在于HTML中的，下面我 们就写个例子来扒一个网页下来。在pycharm里新建一个.py的文件名字叫firstparser.py1234import urllib2response = urllib2.urlopen(&quot;http://www.baidu.com&quot;)print response.read() 是的你没看错，真正的程序就两行，右键选择 run ，查看运行结果，感受一下:看，这个网页的源码已经被我们扒下来了，是不是很酸爽？ 分析扒网页的方法那么我们来分析这两行代码，第一行: response = urllib2.urlopen(&quot;http://www.baidu.com&quot;) 首先我们调用的是urllib2库里面的urlopen方法，传入一个URL，这个网址是百度首页，协议是HTTP协议，当然你也可以把HTTP换做FTP,FILE,HTTPS 等等，只是代表了一种访问控制协议，urlopen一般接受三个参数，它的参数如下： urlopen(url, data, timeout) 第一个参数url即为URL，第二个参数data是访问URL时要传送的数据，第三个timeout是设置超时时间。 第二三个参数是可以不传送的，data默认为空None，timeout默认为 socket._GLOBAL_DEFAULT_TIMEOUT 第一个参数URL是必须要传送的，在这个例子里面我们传送了百度的URL，执行urlopen方法之后，返回一个response对象，返回信息便保存在这里面。 print response.read() response对象有一个read方法，可以返回获取到的网页内容。 构造Requset其实上面的urlopen参数可以传入一个request请求,它其实就是一个Request类的实例，构造时需要传入Url,Data等等的内容。比如上面的两行代码，我们可以这么改写:12345import urllib2request = urllib2.Request(&quot;http://www.baidu.com&quot;)response = urllib2.urlopen(request)print response.read() 运行结果是完全一样的，只不过中间多了一个request对象，推荐大家这么写，因为在构建请求时还需要加入好多内容，通过构建一个request，服务器响应请求得到应答，这样显得逻辑上清晰明确。 POST和GET数据传送上面的程序演示了最基本的网页抓取，不过，现在大多数网站都是动态网页，需要你动态地传递参数给它，数据传送分为POST和GET两种方式: POST我们传送的数据就是这个参数data，下面演示一下POST方式。123456789import urllibimport urllib2values = &#123;&quot;username&quot;:&quot;1016903103@qq.com&quot;,&quot;password&quot;:&quot;XXXX&quot;&#125;data = urllib.urlencode(values)url = &quot;https://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn&quot;request = urllib2.Request(url,data)response = urllib2.urlopen(request)print response.read() 在此只是说明登录的原理。我们需要定义一个字典，名字为values，参数我设置了username和 password，下面利用urllib的urlencode方法将字典编码，命名为data，构建request时传入两个参数，url和data，运 行程序，即可实现登陆，返回的便是登陆后呈现的页面内容。当然你可以自己搭建一个服务器来测试一下。 GET方式至于GET方式我们可以直接把参数写到网址上面，直接构建一个带参数的URL出来即可。123456789101112import urllibimport urllib2values=&#123;&#125;values[&apos;username&apos;] = &quot;1016903103@qq.com&quot;values[&apos;password&apos;]=&quot;XXXX&quot;data = urllib.urlencode(values)url = &quot;http://passport.csdn.net/account/login&quot;geturl = url + &quot;?&quot;+datarequest = urllib2.Request(geturl)response = urllib2.urlopen(request)print response.read() 你可以print geturl，打印输出一下url，发现其实就是原来的url加？然后加编码后的参数1http://passport.csdn.net/account/login?username=1016903103%40qq.com&amp;password=XXXX urllib库的扩展设置Headers有些网站不会同意程序直接用上面的方式进行访问，如果识别有问题，那么站点根本不会响应，所以为了完全模拟浏览器的工作，我们需要设置一些Headers 的属性。 首先，打开我们的浏览器，调试浏览器F12，我用的是Chrome，打开网络监听经过多次请求之后，网页的骨架和肌肉全了，整个网页的效果也就出来了。 拆分这些请求，我们只看一第一个请求，你可以看到，有个Request URL，还有headers，下面便是response，这个头中包含了许许多多是信息，有文件编码啦，压缩方式啦，请求的agent啦等等。 其中，agent就是请求的身份，如果没有写入请求身份，那么服务器不一定会响应，所以可以在headers中设置agent,例如下面的例子，这个例子只是说明了怎样设置的headers，小伙伴们看一下设置格式就好。12345678910111213import urllibimport urllib2url = &apos;http://www.server.com/login&apos;user_agent = &apos;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&apos;values = &#123;&apos;username&apos; : &apos;cqc&apos;,&apos;password&apos; : &apos;XXXX&apos;&#125;headers = &#123; &apos;User-Agent&apos; : user_agent &#125;data = urllib.urlencode(values)request = urllib2.Request(url, data, headers)response = urllib2.urlopen(request)page = response.read() 这样，我们设置了一个headers，在构建request时传入，在请求时，就加入了headers传送，服务器若识别了是浏览器发来的请求，就会得到响应。 另外headers的一些属性，下面的需要特别注意一下：User-Agent : 有些服务器或 Proxy 会通过该值来判断是否是浏览器发出的请求Content-Type : 在使用 REST 接口时，服务器会检查该值，用来确定 HTTP Body 中的内容该怎样解析。application/xml ： 在 XML RPC，如 RESTful/SOAP 调用时使用application/json ： 在 JSON RPC 调用时使用application/x-www-form-urlencoded ： 浏览器提交 Web 表单时使用在使用服务器提供的 RESTful 或 SOAP 服务时， Content-Type 设置错误会导致服务器拒绝服务 Proxy（代理）的设置urllib2 默认会使用环境变量 http_proxy 来设置 HTTP Proxy。假如一个网站它会检测某一段时间某个IP 的访问次数，如果访问次数过多，它会禁止你的访问。所以你可以设置一些代理服务器来帮助你做工作，每隔一段时间换一个代理 创建一个代理处理器ProxyHandlerproxy_support = urllib.request.ProxyHandler()，ProxyHandler是一个类，其参数是一个字典：{ &#39;类型&#39;:&#39;代理ip:端口号&#39;} 定制、创建一个openeropener = urllib.request.build_opener(proxy_support) 使用openerurllib.request.install_opener(opener) opener.open(url) 从代理ip列表中随机使用某ip去访问URL的例子:1234567891011121314import urllib.requestimport randomurl = &apos;http://www.whatismyip.com.tw&apos;iplist = [&apos;115.32.41.100:80&apos;,&apos;58.30.231.36:80&apos;,&apos;123.56.90.175:3128&apos;]proxy_support = urllib.request.ProxyHandler(&#123;&apos;http&apos;:random.choice(iplist)&#125;)opener = urllib.request.build_opener(proxy_support)opener.addheaders = [(&apos;User-Agent&apos;,&apos;Test_Proxy_Python3.5_maminyao&apos;)]urllib.request.install_opener(opener)response = urllib.request.urlopen(url)html = response.read().decode(&apos;utf-8&apos;)print(html) Timeout 设置timeout的设置，可以设置等待多久超时，为了解决一些网站实在响应过慢而造成的影响。import urllib2 response = urllib2.urlopen(&#39;http://www.baidu.com&#39;, timeout=10)]]></content>
      <categories>
        <category>Python</category>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>urllib</tag>
      </tags>
  </entry>
</search>
